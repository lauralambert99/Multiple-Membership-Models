# Data

The data used for this tutorial were simulated in R to loosely represent a cohort of JMU students.  As accurate counts and frequencies of the predictors were not available outside of a request to PAIR, “best guesses” were employed where necessary.  In a fictional scenario, JMU has decided to add a Math Achievement Test as a graduation requirement: students must take this test the semester they anticipate graduating as a measure of their Math Achievement at JMU, with the point of comparison being a cut-score.  The stakes are similar to Assessment Day and there are no penalties for low scores.  JMU, recognizing that many factors may play into how well a student does on this test, wants to consider the role different math teachers play as well as some student-level predictors.  Not wanting this to hold any penalty towards teachers either, JMU has assigned each teacher an anonymous ID and associated it with the years of experience.  JMU is additionally considering what teacher qualities help students be more successful, with the idea of offering more professional development in those areas.  Currently, the only teacher-level predictor available is number of years of experience of the instructor.  

JMU hopes to answer the following research questions: 
RQ1: Do teacher characteristics influence student math scores?
RQ2:  What student characteristics predict math scores?
RQ3:  Does more teacher experience lead to better student outcomes?

The predictors are listed in the table below, along with a brief description.

```{r data table, echo = FALSE, include = FALSE}
df <- data.frame('Predictor' = c("MathAch", "S_ID", "SAT_M", "S_gend", "female, NB", "S_SES", "num_tchrs", "phys", "phys_tchr", "tchr1-tchr12", "w1-w12", "t1_exp-t12_exp"),
                 'Description' = c("Mach Achievement; outcome variable, score on a (fictional) math test given to students", "Student ID; a single number representation of students, from 1 to 5200", "SAT math score; ranges from 200-800 and represents the SAT math score of students prior to entering JMU.", "Student gender; a non-binary gender indicator with 0 = female, 1 = male, and 2 = other/nonbinary/fluid", "Dummy coded student gender, since gender is categorical.  Male is the reference", "Student SES; values range from 2-29", "Number of teachers; the number of math teachers a student had at JMU", "Physics; if a student took physics or not, with 0 = no and 1 = yes", "Physics teacher; if a student took physics, the ID of the teacher they had (ranging from 1 – 22)", "Teachers 1 through 12; teacher IDs (ranging from 1-56) of teachers students had.  If a student had less than 12 teachers, teacher ID = 0", "Weights; these represent the amount of time spent with each teacher.  Values can range from 1 (only had one teacher) to 0.083 (had 12 teachers)", "Teacher experience; Given the compact nature of this dataset, the experience of the first through twelfth teachers of each student is given in years."))

```

```{r data, echo = FALSE, eval = TRUE}

knitr::kable(df, booktabs = TRUE, 
             caption = 'Simulated dataset that will be used for analysis')
```


## Compact vs. wide forms {#compact}

The data are in a .cvs file in “compact” form, as opposed to “wide” form.  Compact form contains two different sets of variables: one set for the first through twelfth teacher to instruct each student and another set represent the multiple membership weight variables.  Wide form would have the same information, but in only one set of variables representing the individual teacher IDs and the proportion of time each teacher spent instructing each student in the cells (see tables below).

### Compact
In compact form, there is a set of variables for the max number of level 2 units encountered, and another set of variables for the weights.  Adding in a level-2 predictor here would only necessitate adding in the appropriate number of columns for the number of level 2 units encountered for that predictor.  Using our data as an example, we have teacher experience as a level 2 predictor, and 12 possible teacher encounters.  To add in teacher experience, we would add in 12 columns, t_exp1-t_exp12, which would populate with the appropriate experience for the teacher the student had.  The weight would be calculated via the weight columns.
```{r compact, include = FALSE, eval = TRUE}
com <- data.frame("Student" = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                "Teacher 1" = c(2, 2, 3, 0, 1, 0, 0, 0, 1, 4),
                "Teacher 2" = c(4, 3, 1, 3, 0, 1, 1, 0, 2, 0),
                "Teacher 3" = c(1, 1, 4, 0, 0, 3, 2, 1, 0, 2),
                "w1" = c(0.33, 0.33, 0.33, 0, 1, 0, 0, 0, 0.5, 0.5),
                "w2" = c(0.33, 0.33, 0.33, 1, 0, 0.5, 0.5, 0, 0.5, 0),
                "w3" = c(0.33, 0.33, 0.33, 0, 0, 0.5, 0.5, 1, 0, 0.5)
                )
```

```{r compact ex, eval = TRUE, echo = FALSE}
knitr::kable(com, booktabs = TRUE, 
             caption = 'Data in compact form')
```
### Wide
While perhaps less evident in this small example, if there were more teacher IDs (56, as in our data for example), but a small number of level 2 units encountered and the associated weights (12 of each in our data), the 'wide' descriptor would become more evident.  The wide descriptor becomes even more evident when considering level two predictors in the model.  In the wide format, every level-2 predictor we add will be calculated across all the level-2 ids.  Using our data as an example, we have teacher experience as a level-2 predictor.  Adding it in using a wide format would mean including 56 columns for the teacher IDs, with weights in the cell to represent the time each student spent with that teacher.  Then, there would be another 56 columns for the teacher experience for each of the teachers, with each of their respective experiences.  
```{r wide, include = FALSE, eval = TRUE}
w <- data.frame("Student" = c(1:10),
                "T1" = c(0.33, 0.33, 0.33, 0, 1, 0.5, 0.5, 1, 0.5, 0),
                "T2" = c(0.33, 0.33, 0, 0, 0, 0, 0.5, 0, 0.5, 0.5),
                "T3" = c(0, 0.33, 0.33, 1, 0, 0.5, 0, 0, 0, 0),
                "T4" = c(0.33, 0, 0.33, 0, 0, 0, 0, 0, 0, 0.5)
                )
```

```{r wide ex, eval = TRUE, echo = FALSE}
knitr::kable(w, booktabs = TRUE, 
             caption = 'Data in wide form')
```

While the wide form is less efficient, some programs require the data to be in one form or the other.  In this instance, MLwiN using Bayesian routines (what we will be using) requires compact form [@Leckie2013]. 


## Examining the Data

The next step is to determine what type of predictors we have and what they look like, as well as if we have a true hierarchical model, a “nesting as nuisance” model, or a non-hierarchical model such as cross-classified or multiple membership models.  We will be looking for if students (in this case) belong to one and only one cluster (teachers), which would indicate a hierarchical approach or perhaps a "nesting as nuisance" approach.  However, if, as is the case, students belong to multiple clusters, we will be taking a non-hierarchical approach.  For this example, we are only considering one cluster, so we will be using a multiple membership design.  We can see in the `num_tchrs` column there are students ranging from having had 1 teacher to 12 teachers, indicating we have a multiple membership column.  We could also look at the `tchr1` through `tchr12` columns, and see there are values in more than one of those - indicating that students have encountered more than one math teacher.

```{r data check, include = TRUE, message = FALSE}
#Read in the data file
StudData <- read.csv("exampledata2.csv")

#See what it looks like
head(StudData)
summary(StudData)

```

We can also see distributions of the outcome and predictors.
```{r outcome, fig.cap = "Distribution of the outcome (Math)", echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}
library(ggplot2)
ggplot(data = StudData) +
  geom_histogram(aes(x = Math)) +
  theme_minimal()
```
```{r predictors1, fig.cap = "Distribution of the number of teachers", echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}
ggplot(data = StudData) +
  geom_histogram(aes(x = num_tchrs)) + 
  theme_minimal()
```
```{r predictors2, fig.cap = "Distribution of Student SES", echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}
ggplot(data = StudData) + 
  geom_histogram(aes(x = S_SES)) +
  theme_minimal()
```
```{r predictors3, fig.cap = "Distribution of Student SAT math scores", echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}
ggplot(data = StudData) +
  geom_histogram(aes(x = SAT_M)) + 
  theme_minimal()
```


## Software Considerations {#software}
MLwiN[@MLwiN] is one of the most commonly found software programs for running multiple membership models, as it can natively handle such complex models.  I have found that SAS and Stata can be 'tricked' into running simple multiple membership models by fitting them as constrained hierarchical models, but with non-continuous outcomes or increased complexity they quickly become computationally inefficient.  More worryingly is that the parameter estimates generated by these methods are found to be biased. The same sources say that R can also be tricked, but I have not found that to be the case [@Stata2013].  That said, both R and Stata have functions or packages that allow you to use their interface and run MLwiN in the background, both to allow use of a familiar interface but also to allow for accurate estimation methods with full model recognition.  MLwiN is not a free software and is produced by the University of Bristol.  A 30-day free trial with full functionality is available to anyone in the world, and for researchers in the US, a single-user license is £400 or a PhD license is available for £225, though it expires after 3 years.  In order to perform the analyses demonstrated below, I obtained a 30-day free license and used the R2MLwiN [@R-R2MLwiN] package to allow me to use an R interface.  While the R code is provided, it will not work unless you also have a valid MLwiN license.

@Heck2022 used OpenBUGS for some more complex multiple membership cross classified modeling of longitudinal data, but at this time OpenBUGS website no longer exists and has been ported to MultiBUGS [@MultiBUGS, @BUGS2020].  One potential drawback of this program is the mis-classification of its software framework by virus detection programs as a virus, leading it to be uninstallable or to throw errors.  MultiBUGS also reports that an R interface (R2MultiBUGS) is under development.

